name: Run Parallel Benchmarks in multiple clients

on:
  workflow_dispatch:
    inputs:
      test:
        description: 'Path to test file'
        default: 'tests/'
      warmup:
        description: 'Name of the warm up file'
        type: choice
        options:
          - ''
          - warmup/warmup-100bl-16wi-32tx.txt
          - warmup/warmup-1000bl-16wi-24tx.txt
          - warmup/warmup-1000bl-16wi-1000tx.txt
        default: 'warmup/warmup-1000bl-16wi-24tx.txt'
      client:
        description: 'Comma-separated list of client names'
        default: 'nethermind,geth,reth,besu,erigon'
      runs:
        description: 'Number of runs for the application'
        default: 1
      images:
        description: 'JSON map of images for the clients'
        default: '{"nethermind":"default","geth":"default","reth":"default","erigon":"default","besu":"default"}'
      opcodes_warmup_count:
        description: 'Number of opcode-warmup iterations'
        default: 2
      filter:
        description: 'Comma-separated include-only filename patterns'
        default: ''
      txt_report:
        description: 'Mark as true to generate txt report'
        default: 'false'

jobs:
  set-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build-matrix.outputs.matrix }}
    steps:
      - name: Build client-only matrix
        id: build-matrix
        run: |
          # Split on commas, build a JSON array of {"client":"..."} entries
          IFS=',' read -ra ARR <<< "${{ github.event.inputs.client }}"
          JSON_ITEMS=$(printf ',{"client":"%s"}' "${ARR[@]}")
          JSON_ITEMS="[${JSON_ITEMS:1}]"
          MATRIX="{\"include\":${JSON_ITEMS}}"

          # Write to the GITHUB_OUTPUT so it becomes an output
          echo "matrix<<EOF" >> $GITHUB_OUTPUT
          echo "$MATRIX"       >> $GITHUB_OUTPUT
          echo "EOF"           >> $GITHUB_OUTPUT

  build:
    needs: set-matrix
    runs-on: ubuntu-latest

    strategy:
      # Consume the JSON matrix we just emitted
      matrix: ${{ fromJson(needs.set-matrix.outputs.matrix) }}

    env:
      DOTNET_INSTALL_DIR: "~/.dotnet"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python & .NET
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '9.0.x'

      - name: Make run.sh executable
        run: chmod +x ./run.sh

      - name: Run benchmarks for client=${{ matrix.client }}
        run: |
          ./run.sh \
            -t "${{ github.event.inputs.test }}" \
            -w "${{ github.event.inputs.warmup }}" \
            -c "${{ matrix.client }}" \
            -r "${{ github.event.inputs.runs }}" \
            -i '${{ github.event.inputs.images }}' \
            -o "${{ github.event.inputs.opcodes_warmup_count }}" \
            -f "${{ github.event.inputs.filter }}"

      - name: Dump latest Docker logs for ${{ matrix.client }}
        if: always()
        run: |
          # Find the newest docker log file for this client
          LATEST=$(ls -1t logs/docker_${{ matrix.client }}_*.log | head -n1 || true)
          if [[ -n "$LATEST" ]]; then
            echo "=== Dumping $LATEST ==="
            cat "$LATEST"
          else
            echo "No docker_*.log files found for client=${{ matrix.client }}"
          fi

      - name: Zip the results folder
        run: |
          CLEANED_RUN=$(echo "${{ matrix.run }}" | tr -d '\n')
          CLEANED_CLIENT=$(echo "${{ matrix.client }}" | tr -d '\n')
          echo "CLEANED_RUN=$CLEANED_RUN" >> $GITHUB_ENV
          echo "CLEANED_CLIENT=$CLEANED_CLIENT" >> $GITHUB_ENV
          zip -r results-${CLEANED_RUN}-${CLEANED_CLIENT}.zip results

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ env.CLEANED_RUN }}-${{ env.CLEANED_CLIENT }}
          path: results-${{ env.CLEANED_RUN }}-${{ env.CLEANED_CLIENT }}.zip
  combine-results:
    needs: build
    runs-on: ubuntu-latest
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Set up .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: "8.0.x"

      - name: Install python dependencies
        run: pip install -r requirements.txt

      - uses: actions/download-artifact@v4
        with:
          path: combined-results
          merge-multiple: true

      - name: Extract all result files
        run: |
          mkdir -p extracted-results
          find combined-results -name '*.zip' -exec unzip -o {} -d extracted-results \;

      - name: Process combined results
        run: |
          runs=${{ github.event.inputs.runs }}
          images="${{ github.event.inputs.images }}"
          if [ -z "$image" ]; then
            python3 report_tables.py --resultsPath extracted-results/results/ --clients "${{ github.event.inputs.client }}" --testsPath ${{ github.event.inputs.test }} --runs $runs 
            python3 report_html.py --resultsPath extracted-results/results/ --clients "${{ github.event.inputs.client }}" --testsPath ${{ github.event.inputs.test }} --runs $runs 
          else
            python3 report_tables.py --resultsPath extracted-results/results/ --clients "${{ github.event.inputs.client }}" --testsPath ${{ github.event.inputs.test }} --runs $runs --images $images
            python3 report_html.py --resultsPath extracted-results/results/ --clients "${{ github.event.inputs.client }}" --testsPath ${{ github.event.inputs.test }} --runs $runs --images $images
          fi

      - name: Generate Report
        if: ${{ github.event.inputs.txt_report == 'true' }}
        run: |
          python3 report_txt.py --resultsPath extracted-results/results/ --clients "${{ github.event.inputs.client }}" --testsPath ${{ github.event.inputs.test }} 

      - name: Zip the results folder
        run: |
          zip -r reports.zip reports

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: reports
          path: reports.zip

  populate-db:
    needs: combine-results
    runs-on: ubuntu-latest
    env:
      DB_HOST: ${{ secrets.PERFNET_0_DB_HOST }}
      DB_PORT: ${{ secrets.PERFNET_0_DB_PORT || '5432' }}
      DB_USER: ${{ secrets.PERFNET_0_DB_USER }}
      DB_PASSWORD: ${{ secrets.PERFNET_0_DB_PASSWORD }}
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install python dependencies for submodule
        run: |
          pip install -r requirements.txt

      - uses: actions/download-artifact@v4
        with:
          path: combined-results # Download artifacts from previous jobs
          merge-multiple: true

      - name: Extract all result files
        run: |
          mkdir -p extracted-results
          find combined-results -name '*.zip' -exec unzip -o {} -d extracted-results \;

      - name: Populate Benchmark DB
        run: |
          python fill_postgres_db.py \
            --db-host ${{ env.DB_HOST }} \
            --db-port ${{ env.DB_PORT }} \
            --db-user ${{ env.DB_USER }} \
            --db-name monitoring \
            --table-name gas_limit_ci \
            --db-password "${{ env.DB_PASSWORD }}" \
            --log-level DEBUG \
            --reports-dir 'extracted-results/reports/'
