name: Run Parallel Benchmarks in multiple clients

on:
  workflow_dispatch:
    inputs:
      test:
        description: 'Path to test file'
        default: 'tests/'
      warmup:
        description: 'Name of the warm up file'
        type: choice
        options:
          - ''
          - warmup/warmup-100bl-16wi-32tx.txt
          - warmup/warmup-1000bl-16wi-24tx.txt
          - warmup/warmup-1000bl-16wi-1000tx.txt
        default: 'warmup/warmup-1000bl-16wi-24tx.txt'
      client:
        description: 'Comma-separated list of client names'
        default: 'nethermind,geth,reth,besu,erigon'
      runs:
        description: 'Number of runs for the application'
        default: 1
      images:
        description: 'JSON map of images for the clients'
        default: '{"nethermind":"default","geth":"default","reth":"default","erigon":"default","besu":"default"}'
      opcodes_warmup_count:
        description: 'Number of opcode-warmup iterations'
        default: 2
      filter:
        description: 'Comma-separated include-only filename patterns'
        default: ''
      txt_report:
        description: 'Mark as true to generate txt report'
        default: 'false'

jobs:
  set-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build-matrix.outputs.matrix }}
    steps:
      - name: Build client-only matrix
        id: build-matrix
        run: |
          # Split on commas, build a JSON array of {"client":"..."} entries
          IFS=',' read -ra ARR <<< "${{ github.event.inputs.client }}"
          JSON_ITEMS=$(printf ',{"client":"%s"}' "${ARR[@]}")
          JSON_ITEMS="[${JSON_ITEMS:1}]"
          MATRIX="{\"include\":${JSON_ITEMS}}"

          # Write to the GITHUB_OUTPUT so it becomes an output
          echo "matrix<<EOF" >> $GITHUB_OUTPUT
          echo "$MATRIX"       >> $GITHUB_OUTPUT
          echo "EOF"           >> $GITHUB_OUTPUT

  build:
    needs: set-matrix
    runs-on: ubuntu-latest

    strategy:
      # Consume the JSON matrix we just emitted
      matrix: ${{ fromJson(needs.set-matrix.outputs.matrix) }}

    env:
      DOTNET_INSTALL_DIR: "~/.dotnet"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python & .NET
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '9.0.x'

      - name: Make run.sh executable
        run: chmod +x ./run.sh

      - name: Run benchmarks for client=${{ matrix.client }}
        run: |
          ./run.sh \
            -t "${{ github.event.inputs.test }}" \
            -w "${{ github.event.inputs.warmup }}" \
            -c "${{ matrix.client }}" \
            -r "${{ github.event.inputs.runs }}" \
            -i '${{ github.event.inputs.images }}' \
            -o "${{ github.event.inputs.opcodes_warmup_count }}" \
            -f "${{ github.event.inputs.filter }}"

      - name: Zip results for ${{ matrix.client }}
        run: |
          zip -r results-${{ matrix.client }}.zip results warmupresults logs reports

      - name: Upload artifact for ${{ matrix.client }}
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.client }}
          path: results-${{ matrix.client }}.zip

  combine-results:
    needs: build
    runs-on: ubuntu-latest
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download all client artifacts
        uses: actions/download-artifact@v4
        with:
          path: combined-results
          merge-multiple: true

      - name: Extract & merge client results
        run: |
          mkdir -p merged-results
          for Z in combined-results/*.zip; do
            TMP=$(mktemp -d)
            unzip -q "$Z" -d "$TMP"
            cp -r "$TMP/results/." merged-results/
          done

      - name: Generate reports
        run: |
          python3 report_tables.py \
            --resultsPath merged-results \
            --clients "${{ github.event.inputs.client }}" \
            --testsPath "${{ github.event.inputs.test }}" \
            --runs "${{ github.event.inputs.runs }}" \
            --images '${{ github.event.inputs.images }}'

          python3 report_html.py \
            --resultsPath merged-results \
            --clients "${{ github.event.inputs.client }}" \
            --testsPath "${{ github.event.inputs.test }}" \
            --runs "${{ github.event.inputs.runs }}" \
            --images '${{ github.event.inputs.images }}'

      - name: (Optional) Generate TXT report
        if: ${{ github.event.inputs.txt_report == 'true' }}
        run: |
          python3 report_txt.py \
            --resultsPath merged-results \
            --clients "${{ github.event.inputs.client }}" \
            --testsPath "${{ github.event.inputs.test }}"

      - name: Zip final reports
        run: zip -r reports.zip reports

      - name: Upload combined reports
        uses: actions/upload-artifact@v4
        with:
          name: reports
          path: reports.zip

  populate-db:
    needs: combine-results
    runs-on: ubuntu-latest
    env:
      DB_HOST: ${{ secrets.PERFNET_0_DB_HOST }}
      DB_PORT: ${{ secrets.PERFNET_0_DB_PORT || '5432' }}
      DB_USER: ${{ secrets.PERFNET_0_DB_USER }}
      DB_PASSWORD: ${{ secrets.PERFNET_0_DB_PASSWORD }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Download & extract final reports
        uses: actions/download-artifact@v4
        with:
          path: extracted
          name: reports

      - name: Populate Benchmark DB
        run: |
          python fill_postgres_db.py \
            --db-host ${{ env.DB_HOST }} \
            --db-port ${{ env.DB_PORT }} \
            --db-user ${{ env.DB_USER }} \
            --db-name monitoring \
            --table-name gas_benchmarks_ci \
            --db-password "${{ env.DB_PASSWORD }}" \
            --log-level DEBUG \
            --reports-dir 'extracted/reports/'
